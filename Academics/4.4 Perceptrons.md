# 4.4 Perceptrons

![[Pasted image 20220927075104.png]]

A perceptron takes a vector of real-valued inputs, calculates a linear combination of these inputs, then outputs a $1$ if the result is greater than some threshold and $-1$ otherwise. More precisely, given inputs $x_1$ through $x_n$, the output $o(x_1, . . . , x_n)$ computed by the perceptron is
			$o(x_1, . . . , x_{n)} = \begin{cases} 1 & if w_{0} + w_{1}x_{1} +...+ w_{n}x_{n}>0 \\ -1 & otherwise\end{cases}$
For brevity, we will sometimes write the perceptron function as
			$o(\vec{x})=sgn(\vec{w}.\vec{x})$
where
			$sgn(y) = \begin{cases}1 & if\ y>0\\-1&otherwise\end{cases}$
Learning a perceptron involves choosing values for the weights $w_0, . . . , w_n$. Therefore, the space H of candidate hypotheses considered in perceptron learning is the set of all possible real-valued weight vectors.

## 4.4.1 Representational Power of Perceptrons
A single perceptron can be used to represent many boolean functions. For example, if we assume boolean values of 1 (true) and -1 (false), then one way to use a two-input perceptron to implement the AND function is to set the weights $w_0 = -.8$, and $w_1 = w_2 = .5.$ This perceptron can be made to represent the OR function instead by altering the threshold to $w_0 = -.3$. In fact, AND and OR can be viewed as special cases of m-of-n functions: that is, functions where at least m of the n inputs to the perceptron must be true. The OR function corresponds to $n = 1$ and the AND function to $m = n$. Any $m-of-n$ function is easily represented using a perceptron by setting all input weights to the same value (e.g., 0.5) and then setting the threshold wo accordingly

Unfortunately, however, some boolean functions cannot be represented by a single perceptron, such as the XOR function whose value is 1 if and only if $x_{1}\neq x_2$.

![[Pasted image 20220927085155.png]]

## 4.4.2 The Perceptron Training Rule
Several algorithms are known to solve this learning problem. Here we consider two: the perceptron rule and the delta rule.

One way to learn an acceptable weight vector is to begin with random weights, then iteratively apply the perceptron to each training example, modifying the perceptron weights whenever it misclassifies an example. This process is repeated, iterating through the training examples as many times as needed until the perceptron classifies all training examples correctly. Weights are modified at each step according to the *perceptron training rule*, which revises the weight wi associated with input $x_i$ according to the rule $w_i\gets w_i+ \Delta w_i$ where $\Delta w_{i}= \eta(t-o)x_i$
Here $t$ is the target output for the current training example, $o$ is the output generated by the perceptron, and $\eta$ is a positive constant called the learning rate

## 4.4.3 Gradient Descent and the Delta Rule
Although the perceptron rule finds a successful weight vector when the training examples are linearly separable, it can fail to converge if the examples are not linearly separable. A second training rule, called the *delta rule*, is designed to overcome this difficulty. If the training examples are not linearly separable, the delta rule converges toward a best-fit approximation to the target concept. The delta training rule is best understood by considering the task of training an unthresholded perceptron; that is, a linear unit for which the output o is given by $o(\vec{x})=\vec{w}.\vec{x}$.
Thus, a linear unit corresponds to the first stage of a perceptron, without the threshold.
$E(\vec{w})\equiv\frac{1}{2}\sum\limits_{d\in D}(t_d-o_d)^2$
where $D$ is the set of training examples, $t_d$ is the target output for training example $d$, and $o_d$ is the output of the linear unit for training example $d$.

## 4.4.3.1 Visualizing the Hypothesis Space

![[Pasted image 20220927092954.png]]

## 4.4.3.2 Derivation of the Gradient Descent Rule

How can we calculate the direction of steepest descent along the error surface? This direction can be found by computing the derivative of E with respect to each component of the vector $\vec{w}$. This vector derivative is called the gradient of $E$ with respect to $\vec{w}$, written $\Delta E(\vec{w})$.





---
# References


---
Date: 27-09-2022
Time: 07:48
Status: #note
Tags: #machinelearning