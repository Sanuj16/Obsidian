# 1.2.4 Choosing a Function Approximation Algorithm

In order to learn target function $\hat{V}$ we require training examples. We need to derive training examples from  indirect training experience and adjust the weights to best fit the model.

## 1.2.4.1 Estimating Training Values

^7c7859

It is harder to assign values to intermediate board states. A surprisingly simple solution is to assign the value of $\hat{V}(Successor(b))$ to the training value of $V_{train}(b)$.
$V_{train}(b) \gets \hat{V}(Successor(b))$

## 1.2.4.2 Adjysting the weights
Weights are adjusted by minimizing the squared error $E$,
$E = \sum\limits_{{b,V_train(b)}\in {training examples}} (V_{train}(b)-\hat{V}(b))^2$ 
In our case, we require an algorithm that will incrementally refine the weights as new training examples become available and that will be robust to errors in these estimated training values. One such algorithm is LMS algorithm. The LMS algorithm is defined as follows:
**LMS weight update rule.**
For each training example $(b, V_train(b))$
- Use the current weights to calculate $\hat{V}(b)$
- For each weight $\omega_i$, update it as
		$\omega_{i} \gets \omega_{i} + \eta(V_{train}(b)-\hat{V}(b))x_i$
Here $\eta$ moderates the size of the weight update.


---
# References


---
Date: 27-09-2022
Time: 04:38
Status: #note
Tags: #machinelearning