# 1.5.1 Performance Metrics and Scalability Analysis

## 1.5.1.1 Performance Metrics
In DS, performance is attributed to many factors. *System throughput* is often measured in MIPS, T*flops* (*tera floaring point operations per second*) or TPS (*transactions per second*). **An interconnection that has low latency and high bandwidth is preferred.** Other performance-related metrics include the *QoS* for Internet and web services; *system availability and dependability*; and* security resilience* for system defense against network attacks.

## 1.5.1.2 Dimensions of Scalability
Users want scalable performance. Any resource upgrade in a system should be backwards compatible. Following are the dimensions of scalability:
- **Size scalability** : Acheiveing higher performance or more functionality by increasing machine size. "Size" means increasing processors, cache, memory storage, or I/O channels.
- **Software scalability** : This refers to upgrades in OS or compilers, adding libraries, porting new application sotware, etc. 
- **Application scalability** : Matching problem size scalability to machine size. An increase in problem size increases the size of data set and workload, which can enhance system efficiency.
- **Technology scalability** : System that can adapt to changes in technologies. For this, one must consider three aspects : 
	- Time: Generational scalability. Changing to a new processor, one must consider its impact on motherboard, etc.
	- Space: is realated to packaging and energy concerns $\gets$ harmony and portabliliy.
	- Heterogeneity: Software from different vendors.

## 1.5.1.3 Scalability versus OS Image Count
Scalable performance implies that the system can achieve higher speed by adding more processors, other hardware components, etc. The OS image is counted by the number of independent OS images observed in a cluster, grid, P2P network, or the cloud. SMP and NUMA are included in the comparison. 
SMP - Symmetric Multiprocessor has single sytem image
NUMA - Nonuniform memory access machines are made out of SMP nodes with distributed, shared memory. 
The cluster nodes can be either SMP servers or high-end machines that are loosely coupled together. Therefore, clusters have much higher scalability than NUMA machines. The number of OS images in a cluster is based on the cluster nodes concurrently in use.
The grid node could be a server cluster, or a mainframe, or a supercomputer, or an MPP. Therefore, the number of OS images in a large grid structure could be hundreds or thousands fewer than the total number of processors in the grid.

![[Pasted image 20220928100640.png]]

## 1.5.1.4 Amdahl's Law
A fraction $\alpha$ of the code executed sequentially is called the *sequential bottleneck*.
$\alpha$ is executed sequentially, (1 - $\alpha$) is parralelly executed by n processors in time $α T + (1 − α)T/n$ where $T$ is total execution time of uniprocessor. 
Amdahl’s Law states that the *speedup factor* of using the n-processor system over the use of a single processor is expressed by:
Speedup = $S = T/(α T + (1 − α)T/n)$ = $1/[α  + (1 − α)/n]$
The maximum speedup of n is achieved only if the sequential bottleneck α is reduced to zero or the code is fully parallelizable with α = 0.
As the cluster becomes sufficiently large, that is, n → ∞, S approaches 1/α, an upper bound on the speedup S.
Amdahl’s law teaches us that we should make the sequential bottleneck as small as possible. Increasing the cluster size alone may not result in a good speedup in this case

## 1.5.1.5 Problem with Fixed Workload
In Amdahl’s law, we have assumed the same amount of workload for both sequential and parallel execution of the program with a fixed problem size or data set. This was called *fixed-workload speedup*. 
To execute a fixed workload on n processors, parallel processing
may lead to a *system efficiency* defined as follows:
$E =S/n =1/[αn + 1 −α]$
The system efficiency is often low, especially low when cluster size(n) is large.
This is because only a few processors (say, 4) are kept busy, while the majority of the nodes are left idling.

## 1.5.1.6 Gustafson’s Law
To achieve higher efficiency when using a large cluster, we must consider scaling the problem size to match the cluster capability. This leads to the following speedup law proposed by John Gustafson (1988), referred as *scaled-workload speedup*. 
$W^′ = αW + (1 − α)nW$
$S^′ = W^′/W =[W + (1− α)nW]/W = α+ (1 −α)n$
$E^′ =S^′/n= α/n+(1− α)$



---
# References


---
Date: 28-09-2022
Time: 09:30
Status: #note
Tags: #cloudcomputing